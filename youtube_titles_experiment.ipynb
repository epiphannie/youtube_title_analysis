{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install altair --channel conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import sys\n",
    "import nltk\n",
    "import pprint\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input_file = 'USvideos.csv'\n",
    "pos_file = 'parts_of_speech.csv'\n",
    "\n",
    "with open(input_file, 'r') as youtube_data:\n",
    "    masterdata_csv = list(csv.reader(youtube_data))\n",
    "\n",
    "with open(pos_file, 'r') as parts_of_speech:\n",
    "    pos_load = csv.reader(parts_of_speech)\n",
    "    pos_dict = {}\n",
    "    for row in pos_load:\n",
    "        pos_dict[row[0]] = row[1]\n",
    "\n",
    "def run_query(query):\n",
    "    return pd.read_sql_query(query,db)\n",
    "\n",
    "def open_db(database):\n",
    "    db = sqlite3.connect(database)\n",
    "    db.execute('PRAGMA foreign_keys = ON;')\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# youtube_pd = pd.read_csv('USvideos.csv', index_col = None, na_values = ['NA'])\n",
    "# masterdata_pd.head(n = 5)\n",
    "# masterdata_pd.tail(n =5)\n",
    "# filtered_yt = youtube_pd[(youtube_pd.title == 'something') & (youtube_pd.views > something else)]\n",
    "#filtered_yt = youtube_pd.filter(items = ['title', 'views'])\n",
    "# youtube_pd.describe() will summarize your data for you\n",
    "# youtube_pd['likes'].describe()\n",
    "# pandas has a merge function, like SQL joins. pd.merge(), supports left right inner outer\n",
    "# .pivot allows for the creation or pivot tables by indicating a row x colum array (child poverty shown with city as the rows and year as the columns)\n",
    "\n",
    "# Can I write derrived data back into a panda data set?\n",
    "# Where does this fit in with the requirements to use SQL?\n",
    "# How does this work library to library? Can I feed panda data into matplotlib? By subsetting, or indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas - Panel Data\n",
    "\n",
    "Rows are a ranges, columns are variables\n",
    "pd.read_csv()\n",
    "put the csv in the repo -- they want to see you download the data to the current working directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create database and master table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try : \n",
    "    os.remove('youtube.db')\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "db = open_db('youtube.db')\n",
    "c = db.cursor()\n",
    "\n",
    "create_statement_master = '''\n",
    "    CREATE TABLE tblMasterData (\n",
    "    id INTEGER AUTOIMCREMENT PRIMARY KEY,\n",
    "    video_id TEXT,\n",
    "    trending_date TEXT,\n",
    "    title TEXT,\n",
    "    channel_title TEXT,\n",
    "    category_id INTEGER,\n",
    "    publish_time INTEGER,\n",
    "    tags TEXT,\n",
    "    views INTEGER,\n",
    "    likes INTEGER,\n",
    "    dislikes INTEGER,\n",
    "    comment_count INTEGER,\n",
    "    thumbnail_link TEXT,\n",
    "    comments_disabled TEXT,\n",
    "    ratings_disabled TEXT,\n",
    "    video_error_or_removed TEXT,\n",
    "    description TEXT)\n",
    "    '''\n",
    "\n",
    "c.execute(create_statement_master)\n",
    "\n",
    "db.commit() # put in a finally (try, except, finally)\n",
    "\n",
    "db.close() # put in a finally (try, except, finally)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save column headers into a dictionary and delete column header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = masterdata_csv[0]\n",
    "headers_dict = {}\n",
    "\n",
    "for count, value in enumerate(headers, 1):\n",
    "    headers_dict[value] = count -1\n",
    "# to keep from 0 indexing my columns\n",
    "\n",
    "del masterdata_csv[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data into master table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>2kyS6SvSYSE</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>CaseyNeistat</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-13T17:13:01.000Z</td>\n",
       "      <td>SHANtell martin</td>\n",
       "      <td>748374</td>\n",
       "      <td>57527</td>\n",
       "      <td>2966</td>\n",
       "      <td>15954</td>\n",
       "      <td>https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SHANTELL'S CHANNEL - https://www.youtube.com/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>1ZAPwfrtAFY</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>LastWeekTonight</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T07:30:00.000Z</td>\n",
       "      <td>last week tonight trump presidency|\"last week ...</td>\n",
       "      <td>2418783</td>\n",
       "      <td>97185</td>\n",
       "      <td>6146</td>\n",
       "      <td>12703</td>\n",
       "      <td>https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>One year after the presidential election, John...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>5qpjK5DgCt4</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>Rudy Mancuso</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-11-12T19:05:24.000Z</td>\n",
       "      <td>racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...</td>\n",
       "      <td>3191434</td>\n",
       "      <td>146033</td>\n",
       "      <td>5339</td>\n",
       "      <td>8181</td>\n",
       "      <td>https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>puqaWrEC7tY</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "      <td>Good Mythical Morning</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T11:00:04.000Z</td>\n",
       "      <td>rhett and link|\"gmm\"|\"good mythical morning\"|\"...</td>\n",
       "      <td>343168</td>\n",
       "      <td>10172</td>\n",
       "      <td>666</td>\n",
       "      <td>2146</td>\n",
       "      <td>https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Today we find out if Link is a Nickelback amat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>d380meD0W0M</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>I Dare You: GOING BALD!?</td>\n",
       "      <td>nigahiga</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-12T18:01:41.000Z</td>\n",
       "      <td>ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...</td>\n",
       "      <td>2095731</td>\n",
       "      <td>132235</td>\n",
       "      <td>1989</td>\n",
       "      <td>17518</td>\n",
       "      <td>https://i.ytimg.com/vi/d380meD0W0M/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>I know it's been a while since we did this sho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id     video_id trending_date  \\\n",
       "0  None  2kyS6SvSYSE      17.14.11   \n",
       "1  None  1ZAPwfrtAFY      17.14.11   \n",
       "2  None  5qpjK5DgCt4      17.14.11   \n",
       "3  None  puqaWrEC7tY      17.14.11   \n",
       "4  None  d380meD0W0M      17.14.11   \n",
       "\n",
       "                                               title          channel_title  \\\n",
       "0                 WE WANT TO TALK ABOUT OUR MARRIAGE           CaseyNeistat   \n",
       "1  The Trump Presidency: Last Week Tonight with J...        LastWeekTonight   \n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...           Rudy Mancuso   \n",
       "3                   Nickelback Lyrics: Real or Fake?  Good Mythical Morning   \n",
       "4                           I Dare You: GOING BALD!?               nigahiga   \n",
       "\n",
       "   category_id              publish_time  \\\n",
       "0           22  2017-11-13T17:13:01.000Z   \n",
       "1           24  2017-11-13T07:30:00.000Z   \n",
       "2           23  2017-11-12T19:05:24.000Z   \n",
       "3           24  2017-11-13T11:00:04.000Z   \n",
       "4           24  2017-11-12T18:01:41.000Z   \n",
       "\n",
       "                                                tags    views   likes  \\\n",
       "0                                    SHANtell martin   748374   57527   \n",
       "1  last week tonight trump presidency|\"last week ...  2418783   97185   \n",
       "2  racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...  3191434  146033   \n",
       "3  rhett and link|\"gmm\"|\"good mythical morning\"|\"...   343168   10172   \n",
       "4  ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...  2095731  132235   \n",
       "\n",
       "   dislikes  comment_count                                  thumbnail_link  \\\n",
       "0      2966          15954  https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg   \n",
       "1      6146          12703  https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg   \n",
       "2      5339           8181  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
       "3       666           2146  https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg   \n",
       "4      1989          17518  https://i.ytimg.com/vi/d380meD0W0M/default.jpg   \n",
       "\n",
       "  comments_disabled ratings_disabled video_error_or_removed  \\\n",
       "0             False            False                  False   \n",
       "1             False            False                  False   \n",
       "2             False            False                  False   \n",
       "3             False            False                  False   \n",
       "4             False            False                  False   \n",
       "\n",
       "                                         description  \n",
       "0  SHANTELL'S CHANNEL - https://www.youtube.com/s...  \n",
       "1  One year after the presidential election, John...  \n",
       "2  WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...  \n",
       "3  Today we find out if Link is a Nickelback amat...  \n",
       "4  I know it's been a while since we did this sho...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = open_db('youtube.db')\n",
    "c = db.cursor()\n",
    "\n",
    "c.executemany('''\n",
    "INSERT INTO tblMasterData\n",
    "(video_id,\n",
    "trending_date,\n",
    "title,\n",
    "channel_title,\n",
    "category_id,\n",
    "publish_time,\n",
    "tags,\n",
    "views,\n",
    "likes,\n",
    "dislikes,\n",
    "comment_count,\n",
    "thumbnail_link,\n",
    "comments_disabled,\n",
    "ratings_disabled,\n",
    "video_error_or_removed,\n",
    "description)\n",
    "VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)\n",
    "''', \n",
    "masterdata_csv)\n",
    "\n",
    "db.commit()\n",
    "\n",
    "master_limit5 = run_query('SELECT * FROM tblMasterData LIMIT 5;')\n",
    "\n",
    "db.close()\n",
    "\n",
    "master_limit5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After reviewing master data, create two tables based on function -- one static, one transactional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = open_db('youtube.db')\n",
    "c = db.cursor()\n",
    "\n",
    "create_statement_video = '''\n",
    "    CREATE TABLE tblVideos (\n",
    "    video_id TEXT PRIMARY KEY NOT NULL,\n",
    "    title TEXT NOT NULL,\n",
    "    channel_title TEXT NOT NULL,\n",
    "    publish_time INTEGER NOT NULL,\n",
    "    tags TEXT NOT NULL,\n",
    "    thumbnail_link TEXT NOT NULL,\n",
    "    comments_disabled TEXT NOT NULL,\n",
    "    ratings_disabled TEXT NOT NULL,\n",
    "    video_error_or_removed TEXT NOT NULL,\n",
    "    description TEXT NOT NULL)\n",
    "    '''\n",
    "\n",
    "c.execute(create_statement_video)\n",
    "\n",
    "create_statement_time = '''\n",
    "    CREATE TABLE tblTime (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    video_id TEXT NOT NULL,\n",
    "    trending_date TEXT NOT NULL,\n",
    "    views INTEGER NOT NULL,\n",
    "    likes INTEGER NOT NULL,\n",
    "    dislikes INTEGER NOT NULL,\n",
    "    comment_count INTEGER NOT NULL,\n",
    "        FOREIGN KEY(video_id) REFERENCES tblVideos(video_id))\n",
    "    '''\n",
    "\n",
    "c.execute(create_statement_time)\n",
    "\n",
    "db.commit()\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date is stored in hard-to-read format. Transform date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in masterdata_csv:\n",
    "    date = row[headers_dict['trending_date']]\n",
    "    updated_date = \"20\" + date[:2]\n",
    "    updated_date += \"-\"\n",
    "    updated_date += date[6:]\n",
    "    updated_date += \"-\"\n",
    "    updated_date += date[3:5]\n",
    "    row[headers_dict['trending_date']] = updated_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titles contain characters + and &. These will not be parseable. Replacing with 'and'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in masterdata_csv:\n",
    "    title = row[headers_dict['title']]\n",
    "    updated_title = re.sub('&|\\+', 'and', title)\n",
    "    row[headers_dict['title']] = updated_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate CSV file into lists to be loaded to each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_data = []\n",
    "time_data = []\n",
    "\n",
    "for row in masterdata_csv:\n",
    "    video_entry = [row[headers_dict['video_id']], \n",
    "                   row[headers_dict['title']], \n",
    "                   row[headers_dict['channel_title']], \n",
    "                   row[headers_dict['publish_time']],\n",
    "                   row[headers_dict['tags']],\n",
    "                   row[headers_dict['thumbnail_link']],\n",
    "                   row[headers_dict['comments_disabled']],\n",
    "                   row[headers_dict['ratings_disabled']],\n",
    "                   row[headers_dict['video_error_or_removed']],\n",
    "                   row[headers_dict['description']]\n",
    "                  ]\n",
    "    \n",
    "    video_data.append(video_entry)\n",
    "    \n",
    "    time_entry = [row[headers_dict['video_id']], \n",
    "                  row[headers_dict['trending_date']], \n",
    "                  row[headers_dict['views']], \n",
    "                  row[headers_dict['likes']],\n",
    "                  row[headers_dict['dislikes']],\n",
    "                  row[headers_dict['comment_count']]\n",
    "                 ]\n",
    "    \n",
    "    time_data.append(time_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data to tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = open_db('youtube.db')\n",
    "c = db.cursor()\n",
    "\n",
    "c.executemany('''\n",
    "        INSERT OR REPLACE INTO tblVideos\n",
    "        (video_id,\n",
    "        title,\n",
    "        channel_title,\n",
    "        publish_time,\n",
    "        tags,\n",
    "        thumbnail_link,\n",
    "        comments_disabled,\n",
    "        ratings_disabled,\n",
    "        video_error_or_removed,\n",
    "        description)\n",
    "        VALUES (?,?,?,?,?,?,?,?,?,?)\n",
    "        ''', \n",
    "        video_data)\n",
    "\n",
    "db.commit()\n",
    "    \n",
    "c.executemany('''\n",
    "        INSERT INTO tblTime\n",
    "        (video_id,\n",
    "        trending_date,\n",
    "        views,\n",
    "        likes,\n",
    "        dislikes,\n",
    "        comment_count)\n",
    "        VALUES (?,?,?,?,?,?)\n",
    "        ''', \n",
    "        time_data)\n",
    "\n",
    "db.commit()\n",
    "\n",
    "videos_limit5 = run_query('SELECT * FROM tblVideos LIMIT 5;')\n",
    "\n",
    "time_limit5 = run_query ('SELECT * FROM tblTime LIMIT 5;')\n",
    "\n",
    "db.close()\n",
    "\n",
    "# to view a sample, uncomment below\n",
    "# videos_limit5\n",
    "# time_limit5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for foreign key failure  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'sqlite3.IntegrityError'>, IntegrityError('FOREIGN KEY constraint failed',), <traceback object at 0x1a14f01e48>)\n"
     ]
    }
   ],
   "source": [
    "db = open_db('youtube.db')\n",
    "c = db.cursor()\n",
    "\n",
    "try:\n",
    "    c.execute(\"INSERT INTO tblTime VALUES (?, ?, ?, ?, ?, ?, ?)\", (None, \"testy\", \"18.11.11\", 1, 1, 1, 1))\n",
    "except:\n",
    "    print(sys.exc_info())\n",
    "\n",
    "db.commit()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ^ look at that! It failed!!! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titles appear to come in multiple segments, divided by special characters. Create Segments table to store segments of each title for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = open_db('youtube.db')\n",
    "c = db.cursor()\n",
    "\n",
    "create_statement_segments = '''\n",
    "    CREATE TABLE tblSegments (\n",
    "    segment_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    video_id TEXT NOT NULL,\n",
    "    segment_text TEXT NOT NULL,\n",
    "    segment_structure TEXT,\n",
    "        FOREIGN KEY(video_id) REFERENCES tblVideos(video_id))\n",
    "    '''\n",
    "\n",
    "c.execute(create_statement_segments)\n",
    "\n",
    "db.commit()\n",
    "db.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define classes to facilitate analaysis...and for practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Video:\n",
    "    \n",
    "    def __init__(self, video_id, title):\n",
    "        self.video_id = video_id\n",
    "        self.title = title\n",
    "    \n",
    "    def longest_word(self):\n",
    "        longest_length = 0\n",
    "        longest_word = ''\n",
    "        for word in self.title:\n",
    "            if len(word) > longest_length:\n",
    "                longest_length = len(word)\n",
    "                longest_word = word\n",
    "            else:\n",
    "                continue\n",
    "        return longest_word\n",
    "\n",
    "    def title_segments(self):\n",
    "        list = re.compile(\"(?:\\||(?:\\s-\\s)|—|:|\\(|\\)|\\[|\\]|{|})+\").split(self.title)\n",
    "        # ?: indicates a non-capture group so delimiters aren't saved. Now I know.\n",
    "        list = filter(lambda x: x != None, list)\n",
    "        #  python is returning None where the delimiter was. Removing Nones.\n",
    "        segments = []\n",
    "        for text in list:\n",
    "            text = text.strip()\n",
    "            if text == \"\":\n",
    "                continue\n",
    "            segments.append(Segment(self.video_id, text))\n",
    "        return segments\n",
    "\n",
    "    \n",
    "class Segment:\n",
    "    \n",
    "    def __init__(self, video_id, text):\n",
    "        self.video_id = video_id\n",
    "        self._text = text\n",
    "        \n",
    "    def text(self):\n",
    "        return re.sub('[^A-Za-z0-9\\s\\-\\']+', '', self._text)\n",
    "    \n",
    "    def words(self):\n",
    "        list = self.text().split()\n",
    "        list = filter(lambda x: x != None, list)\n",
    "        #  python is returning None where the delimiter was. Removing Nones.\n",
    "        segments = []\n",
    "        for item in list:\n",
    "            text = item.strip()\n",
    "            if text == \"\":\n",
    "                continue\n",
    "            segments.append(text)\n",
    "        return segments\n",
    "    \n",
    "    def parts_of_speech(self):\n",
    "        text = nltk.word_tokenize(self.text())\n",
    "        tagged_text = nltk.pos_tag(text)\n",
    "        #  creates list of tuples with (word, part of speech)\n",
    "        return [item[1] for item in tagged_text]\n",
    "\n",
    "class Title_glob:\n",
    "    \n",
    "    def __init__(self, glob):\n",
    "        self.glob = glob\n",
    "    \n",
    "    def word_list(self):\n",
    "        return self.glob\n",
    "    \n",
    "    def frequency_distribution(self):\n",
    "        return nltk.FreqDist(self.glob)\n",
    "    \n",
    "    def lexical_diversity(self):\n",
    "        return len(set(self.glob)) / len(self.glob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select data from Videos table to parse into segments and commit to Segments table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = open_db('youtube.db')\n",
    "c = db.cursor()\n",
    "\n",
    "c.execute(\"SELECT video_id, title FROM tblVideos;\")\n",
    "titles_list = c.fetchall()\n",
    "\n",
    "db.commit()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_entries=[]\n",
    "\n",
    "for row in titles_list:\n",
    "    video = Video(row[0], row[1])\n",
    "    segments = video.title_segments()\n",
    "    for segment in segments:\n",
    "        segment_entry = []\n",
    "        segment_entry.append(segment.video_id)\n",
    "        segment_entry.append(segment.text())\n",
    "        segment_entry.append(\", \".join(segment.parts_of_speech()))\n",
    "        segment_entries.append(segment_entry)\n",
    "        \n",
    "# it thinks they're all proper nouns. title probs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>segment_text</th>\n",
       "      <th>segment_structure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10166</td>\n",
       "      <td>RxvcH25WThg</td>\n",
       "      <td>ESPN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10167</td>\n",
       "      <td>hYOa56nwx5Y</td>\n",
       "      <td>What Are Fever Dreams</td>\n",
       "      <td>WP, VBP, NNP, NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10168</td>\n",
       "      <td>4_eVvzrTV-I</td>\n",
       "      <td>Shaquem Griffin Gets Selected by the Seattle S...</td>\n",
       "      <td>NNP, NNP, NNP, VBN, IN, DT, NNP, NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10169</td>\n",
       "      <td>4_eVvzrTV-I</td>\n",
       "      <td>2018 NFL Draft</td>\n",
       "      <td>CD, NNP, NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10170</td>\n",
       "      <td>lE0eWRdSrY4</td>\n",
       "      <td>Koreas</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   segment_id     video_id                                       segment_text  \\\n",
       "0       10166  RxvcH25WThg                                               ESPN   \n",
       "1       10167  hYOa56nwx5Y                              What Are Fever Dreams   \n",
       "2       10168  4_eVvzrTV-I  Shaquem Griffin Gets Selected by the Seattle S...   \n",
       "3       10169  4_eVvzrTV-I                                     2018 NFL Draft   \n",
       "4       10170  lE0eWRdSrY4                                             Koreas   \n",
       "\n",
       "                      segment_structure  \n",
       "0                                    NN  \n",
       "1                     WP, VBP, NNP, NNP  \n",
       "2  NNP, NNP, NNP, VBN, IN, DT, NNP, NNP  \n",
       "3                          CD, NNP, NNP  \n",
       "4                                   NNS  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = open_db('youtube.db')\n",
    "c = db.cursor()\n",
    "\n",
    "c.executemany('''\n",
    "        INSERT INTO tblSegments\n",
    "        (video_id,\n",
    "        segment_text,\n",
    "        segment_structure)\n",
    "        VALUES (?,?, ?)\n",
    "        ''', \n",
    "        segment_entries)\n",
    "\n",
    "select_segments = run_query('SELECT * FROM tblSegments WHERE segment_id>=(abs(random()) % (SELECT max(segment_id)FROM tblSegments)) LIMIT 5')\n",
    "\n",
    "db.commit()\n",
    "db.close()\n",
    "\n",
    "select_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = open_db('youtube.db')\n",
    "c = db.cursor()\n",
    "\n",
    "c.execute(\"SELECT video_id, segment_text, segment_id FROM tblSegments LIMIT 5;\")\n",
    "segments_list = c.fetchall()\n",
    "\n",
    "db.commit()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate all segments for analysis as a whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '103-yd', 'before', \"can't-miss\", 'dceu', 'denver', 'dion', 'every', 'highlights', 'justice', 'kick', 'league', \"lewis'\", 'movie', 'nfl', 'play', 'return', 'td', 'tldw', 'vs', 'wk']\n",
      "['10', '103-yd', 'before', \"can't-miss\", 'dceu', 'denver', 'dion', 'every', 'highlights', 'justice', 'kick', 'league', \"lewis'\", 'movie', 'nfl', 'play', 'return', 'td', 'tldw', 'vs', 'wk']\n"
     ]
    }
   ],
   "source": [
    "def lower_case(list):\n",
    "    return [w.lower() for w in list]\n",
    "\n",
    "all_segment_words = []\n",
    "\n",
    "for item in segments_list:\n",
    "    segment = Segment(item[0], item[1])\n",
    "    segment_words = segment.words()\n",
    "    for word in segment_words: \n",
    "        all_segment_words.append(word)\n",
    "\n",
    "all_segment_words = lower_case(all_segment_words)\n",
    "\n",
    "all_words = Title_glob(sorted(all_segment_words))\n",
    "print(all_words.word_list())\n",
    "\n",
    "all_tokens = Title_glob(sorted(set(all_segment_words)))\n",
    "print(all_tokens.word_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The X most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_dist = title_glob.frequency_distribution()\n",
    "# print(freq_dist.most_common(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The length of the set of unique words / the length of the text. Fairly Unique!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title_glob.lexical_diversity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "- concat titles for fun analysis\n",
    "- search nltk for stuff to make classes work\n",
    "\n",
    "Fun stuff to report:\n",
    "- Avg. title segments per title\n",
    "- Longest word per title\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
